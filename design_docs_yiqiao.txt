1. client files local searching and cached (on disk)
cache update algorithms (both server and client)

consider using Redis as local cache
python redis library!

缓存文件淘汰算法，100%
读写锁区分以及函数对应的逻辑，50%
多个server的一致性paxos实现，
访问服务器的负载均衡算法/流量管理算法

in conclusion: 
    write/read operation for the cache directory is changed to the
    write/read operation for the redis cache database

2. consistency on multiple machines 
(paxos/raft, paxos chose)
Preliminary:
    one main Proposer chose
    Learner: seems not used in our system (accepting the value agreed by the Acceptor) 
    Proposer(N,V)
    Acceptor(ResN, AcceptN, AcceptV)
Stage 1:
    Proposer:
        send prepare(id:N) to Acceptor
    Acceptor:
        N <= ResN:
            error / ignore
        N > ResN:
            ResN = N
            response: 
                (Pok, AcceptN, AcceptV) or (Pok, null, null)
                
Stage 2:
    Proposer:
        sum(Pok) > num_node / 2:
            if received AcceptV:
                V = AcceptV of argmax_N{AcceptN}
            else (all is null):
                V = ProposerV
            send accept(N,V)
        sum(Pok) <= num_node / 2:
            return to Stage 1
    Acceptor:
        N > ResN:
            Accept, AcceptN = N, AcceptV = V, response: Aok
        N <= ResN:
            error / ignore
    ----------------------------
    Proposer:
        sum(Aok) > num_node / 2:
            confirmed V is chose
        sum(Aok) <= num_node / 2:
            return to Stage 1


3. flow control algorithms 
(client access control)

on the basis of workload balancing algorithms:
previous algorithm:
    download: 
        weights for each node, init to 0
        effective weight:
            node abnormality: weight--
            normally called: weight++
        configured weight
        total weight update rule:
            weight_c_i+1 = weight_c_i - sum_j(weight_j_i)
    upload: 
        original algorithm: 
            depend on the number of files of each node (not applicable)

        my upgrade to flow control:
            compute each node's ping timestamp with the client
                distributed to smaller distance nodes
            get the access flow information of each node 
                distributed to lower accessed nodes
                (equal access number for each node)
